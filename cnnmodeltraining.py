# -*- coding: utf-8 -*-
"""CNNModelTraining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gGZKiAYscBzi2NIFZmf81pbFBn6sHhXA
"""

from zipfile import ZipFile
import os

# Replace 'your_extraction_folder' with the folder where you want to extract the contents
extraction_folder = '/content/newfyp'

# Replace 'your_zip_file.zip' with the actual filename
zip_file_path = '/content/newfyp.zip'

# Unzip the file
try:
    with ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extraction_folder)
    print(f"Files successfully extracted to {extraction_folder}")
except Exception as e:
    print(f"An error occurred: {e}")

# List files in the extraction folder
try:
    files_in_extraction_folder = os.listdir(extraction_folder)
    print(f"Files in the extraction folder: {files_in_extraction_folder}")
except FileNotFoundError:
    print(f"Extraction folder not found: {extraction_folder}")
except Exception as e:
    print(f"An error occurred while listing files: {e}")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

# Define paths to the datasets
train_dir = '/content/newfyp/newfyp/newfyp/fyp/Training (70%)'
validation_dir = '/content/newfyp/newfyp/newfyp/fyp/Validation (10%)'
test_dir = '/content/newfyp/newfyp/newfyp/fyp/Testing (20%)'

# Set parameters
img_width, img_height = 150, 150
input_shape = (img_width, img_height, 3)
batch_size = 16
epochs = 128

# Define data generators
train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
validation_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_width, img_height),
                                                    batch_size=batch_size, class_mode='categorical',
                                                    shuffle=True)

validation_generator = validation_test_datagen.flow_from_directory(validation_dir, target_size=(img_width, img_height),
                                                                  batch_size=batch_size, class_mode='categorical')

# Build the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(4, activation='softmax'))  # Assuming 4 classes

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_generator, steps_per_epoch=max(1, train_generator.samples // batch_size),
                    epochs=epochs, validation_data=validation_generator,
                    validation_steps=max(1, validation_generator.samples // batch_size))

# Save the class indices to use for later predictions
class_indices = train_generator.class_indices
index_to_class = {v: k for k, v in class_indices.items()}

# Evaluate on the test set
test_generator = validation_test_datagen.flow_from_directory(test_dir, target_size=(img_width, img_height),
                                                             batch_size=batch_size, class_mode='categorical', shuffle=False)

# Make sure we predict on all images
steps = test_generator.samples // batch_size + (test_generator.samples % batch_size > 0)
predictions = model.predict(test_generator, steps=steps)
# Convert predictions to class names
predicted_classes_indices = np.argmax(predictions, axis=1)
predicted_classes_names = [index_to_class[idx] for idx in predicted_classes_indices]

# Output the predictions for each test image
for i in range(len(predicted_classes_names)):
    # Get the file path for the current index
    file_path = test_generator.filepaths[i % len(test_generator.filepaths)]
    print(f"Image: {file_path.split('/')[-1]} - Class: {predicted_classes_names[i]}")

# Print the test accuracy
test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)
print(f"Test Accuracy: {test_accuracy}")

for i, prediction in enumerate(predictions):
    print(f"Image {i}:")
    for class_index, prob in enumerate(prediction):
        class_name = index_to_class[class_index]  # Get the class name using the index_to_class dictionary
        print(f"    {class_name}: {prob*100:.2f}%")
    print("\n")

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Get the true class indices
true_classes = test_generator.classes

# Predicted class indices were obtained previously as `predicted_classes_indices`

# Generate the confusion matrix
cm = confusion_matrix(true_classes, predicted_classes_indices)

# Convert class indices to class names for the confusion matrix
class_names = [index_to_class[i] for i in range(len(index_to_class))]

# Plotting the confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Save the model to a file
model.save('my_cnn_model_updated(latest).h5')  # Saves the model in HDF5 format

from google.colab import files
files.download('my_cnn_model_updated(latest).h5')